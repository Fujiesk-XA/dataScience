{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport random as rd\nimport seaborn as sns\nimport statistics as st\nimport statsmodels.api as sm\nimport tensorflow as tf\n\nfrom scipy.stats import skew\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.metrics import classification_report, mean_squared_error, mean_absolute_error, r2_score\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import LinearSVR, SVR\n\nsns.set()\nmpl.style.use('classic')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Happiness_Index():\n    \n    country = ''\n    file_data = ''\n    file_data_preprocessed = ''\n    file_name = ''\n    iso_alpha2 = ''\n    iso_alpha3 = ''\n    iso_numeric = ''\n    iso2_alpha2 = ''\n    region = ''\n    score = ''    \n    year = ''\n    \n    region_countries = {}\n\n    def get_by_country_alpha2(self, filter_country):\n        \n        return self.file_data[(self.file_data['ISO_3166-1_Alpha2'] == filter_country)]\n    \n    def get_by_country_alpha3(self, filter_country):\n        \n        return self.file_data[(self.file_data['ISO_3166-1_Alpha3'] == filter_country)]\n    \n    def get_by_country_numeric(self, filter_country):\n        \n        return self.file_data[(self.file_data['ISO_3166-1_Numeric'] == filter_country)]\n    \n    def get_by_country_iso2(self, filter_country):\n        \n        return self.file_data[(self.file_data['ISO_3166-2'] == filter_country)]    \n    \n    def get_by_region(self, filter_region):\n        \n        return self.file_data[(self.file_data['Region'] == filter_region)]\n    \n    def get_by_year(self, filter_year):\n        \n        return self.file_data[(self.file_data['Year'] == filter_year)]\n    \n    def load_file(self):\n        \n        self.file_data = pd.read_csv(self.file_name)\n        \n        self.year = self.file_data['Year']\n        self.iso_alpha2 = self.file_data['ISO_3166-1_Alpha2']\n        self.iso_alpha3 = self.file_data['ISO_3166-1_Alpha3']\n        self.iso_numeric = self.file_data['ISO_3166-1_Numeric']\n        self.iso2_alpha2 = self.file_data['ISO_3166-2']\n        self.country = self.file_data['Country']\n        self.region = self.file_data['Region']\n        self.score = self.file_data['Score']\n        \n        for region in self.region.unique():\n    \n            countries = self.get_by_region(region)    \n            country_names = countries['Country'].unique()    \n            self.region_countries[region] = country_names\n            \n        self.file_data.info()    \n    \n    def normalize_data(self):\n        \n        features_to_normalize = happiness_index.file_data[['Score']]\n\n        normalized_features = normalize(features_to_normalize)\n\n        normalized_features_df = pd.DataFrame(normalized_features, columns = ['Score_Nml'])\n\n        happiness_index.file_data['Score_Nml'] = normalized_features_df['Score_Nml']\n\n    def standardize_data(self):\n        \n        features_to_scale = happiness_index.file_data[['Score']]\n\n        scaler = StandardScaler()\n        scaler.fit(features_to_scale)\n        scaled_features = scaler.transform(features_to_scale)\n\n        scaled_features_df = pd.DataFrame(scaled_features, columns = ['Score_Std'])\n\n        happiness_index.file_data['Score_Std'] = scaled_features_df['Score_Std']\n        \n    def __init__(self):\n        \n        pass\n\nhappiness_index = Happiness_Index()\nhappiness_index.file_name = '../input/happiness-index-dataset/Happiness_Index_Master.csv'\nhappiness_index.load_file()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Health_Care(Happiness_Index):\n    \n    Spend_GDP = ''\n    Spend_Out_Of_Pocket = ''\n    Spend_Per_Capita = ''\n    Spend_Per_Capita_PPP = ''\n    Spend_Public = ''\n    Nurse_per_1000 = ''\n    Physicians_per_1000 = ''\n    \n    Optimal_Features = []\n    Optimal_Happiness = 0\n    \n    def load_file(self):\n        \n        self.file_data = pd.read_csv(self.file_name)\n        \n        self.year = 2016\n        self.iso_alpha2 = self.file_data['ISO_3166-1_Alpha2']\n        self.iso_alpha3 = self.file_data['ISO_3166-1_Alpha3']\n        self.iso_numeric = self.file_data['ISO_3166-1_Numeric']\n        self.iso2_alpha2 = self.file_data['ISO_3166-2']\n        self.country = self.file_data['Country']\n        self.region = self.file_data['Region']\n        self.score = self.file_data['Score']\n        self.Spend_GDP = self.file_data['Spend_GDP']\n        self.Spend_Out_Of_Pocket = self.file_data['Spend_Out_Of_Pocket']\n        self.Spend_Per_Capita = self.file_data['Spend_Per_Capita']\n        self.Spend_Per_Capita_PPP = self.file_data['Spend_Per_Capita_PPP']\n        self.Spend_Public = self.file_data['Spend_Public']\n        self.Nurse_per_1000 = self.file_data['Nurse_per_1000']\n        self.Physicians_per_1000 = self.file_data['Physicians_per_1000']\n        \n        \n        for region in self.region.unique():\n    \n            countries = self.get_by_region(region)    \n            country_names = countries['Country'].unique()    \n            self.region_countries[region] = country_names\n            \n        self.file_data.info() \n    \n    def run_algorithm(self, \\\n                      algorithm, \\\n                      predictive_features_train, \\\n                      predictive_features_test, \\\n                      targets_train, \\\n                      targets_test, \\\n                      algorithm_description):\n\n        predictive_model = algorithm\n        predictive_model.fit(predictive_features_train, targets_train)        \n        \n        print(algorithm_description, 'Correlation: ', predictive_model.score(predictive_features_test, targets_test))\n        \n        for count in range(1, 100000):\n            \n            hypothetical_features = np.array([[rd.uniform(min(predictive_features_train[0]), max(predictive_features_train[0])), \\\n                                             rd.uniform(min(predictive_features_train[1]), max(predictive_features_train[1])), \\\n                                             rd.uniform(min(predictive_features_train[2]), max(predictive_features_train[2])), \\\n                                             rd.uniform(min(predictive_features_train[3]), max(predictive_features_train[3])), \\\n                                             rd.uniform(min(predictive_features_train[4]), max(predictive_features_train[4])), \\\n                                             rd.uniform(min(predictive_features_train[5]), max(predictive_features_train[5])), \\\n                                             rd.uniform(min(predictive_features_train[6]), max(predictive_features_train[6]))]])\n            \n            happiness_score = predictive_model.predict(hypothetical_features)\n            \n            if happiness_score > self.Optimal_Happiness:\n                \n                self.Optimal_Features = hypothetical_features\n                self.Optimal_Happiness = happiness_score\n                \n        print(self.Optimal_Features)\n        print(self.Optimal_Happiness)\n    \n    def regression_models(self):\n\n        targets = self.file_data.loc[:, 'Score']\n        predictive_features = self.file_data.loc[:,\\\n        ['Spend_GDP', 'Spend_Out_Of_Pocket', 'Spend_Per_Capita', 'Spend_Per_Capita_PPP', 'Spend_Public', 'Nurse_per_1000', 'Physicians_per_1000']]\n\n        predictive_features_train, \\\n        predictive_features_test, \\\n        targets_train, \\\n        targets_test = train_test_split(predictive_features, \\\n                                        targets, test_size = 0.2, \\\n                                        random_state = 42)\n\n        targets_train = np.ravel(targets_train)\n\n        scaler = StandardScaler()\n\n        scaler.fit(predictive_features_train)\n        predictive_features_train_scaled = scaler.transform(predictive_features_train)\n        predictive_features_test_scaled = scaler.transform(predictive_features_test)\n\n        self.run_algorithm(LinearRegression(), \\\n                      predictive_features_train_scaled, \\\n                      predictive_features_test_scaled, \\\n                      targets_train, \\\n                      targets_test, \\\n                      'Linear Regression')\n        \n        self.run_algorithm(Ridge(), \\\n                      predictive_features_train_scaled, \\\n                      predictive_features_test_scaled, \\\n                      targets_train, \\\n                      targets_test, \\\n                      'Ridge')\n        \n        self.run_algorithm(SVR(), \\\n                      predictive_features_train_scaled, \\\n                      predictive_features_test_scaled, \\\n                      targets_train, \\\n                      targets_test, \\\n                      'Suport Vector Regression')\n    \n    \n    def __init__(self):\n        \n        pass\n    \nhealth_care = Health_Care()\nhealth_care.file_name = '../input/health-care/Health_Care.csv'\nhealth_care.load_file()","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"constant = sm.add_constant(health_care.Spend_GDP)\nregression_result = sm.OLS(health_care.score, constant).fit()\nprint(regression_result.summary())\n \nplt.scatter(health_care.Spend_GDP, health_care.score)\nregression_function = regression_result.params[1] * health_care.Spend_GDP + regression_result.params[0]\nregression_line = plt.plot(health_care.Spend_GDP, regression_function, lw = 5, c = 'red', label = 'Regression Line')\nplt.xlabel('Spend_GDP', fontsize = 15)\nplt.ylabel('score', fontsize = 15)\nplt.show()\n\nconstant = sm.add_constant(health_care.Spend_Out_Of_Pocket)\nregression_result = sm.OLS(health_care.score, constant).fit()\nprint(regression_result.summary())\n \nplt.scatter(health_care.Spend_Out_Of_Pocket, health_care.score)\nregression_function = regression_result.params[1] * health_care.Spend_Out_Of_Pocket + regression_result.params[0]\nregression_line = plt.plot(health_care.Spend_Out_Of_Pocket, regression_function, lw = 5, c = 'red', label = 'Regression Line')\nplt.xlabel('Spend_Out_Of_Pocket', fontsize = 15)\nplt.ylabel('score', fontsize = 15)\nplt.show()\n\nconstant = sm.add_constant(health_care.Spend_Per_Capita)\nregression_result = sm.OLS(health_care.score, constant).fit()\nprint(regression_result.summary())\n \nplt.scatter(health_care.Spend_Per_Capita, health_care.score)\nregression_function = regression_result.params[1] * health_care.Spend_Per_Capita + regression_result.params[0]\nregression_line = plt.plot(health_care.Spend_Per_Capita, regression_function, lw = 5, c = 'red', label = 'Regression Line')\nplt.xlabel('Spend_Per_Capita', fontsize = 15)\nplt.ylabel('score', fontsize = 15)\nplt.show()\n\nconstant = sm.add_constant(health_care.Spend_Per_Capita_PPP)\nregression_result = sm.OLS(health_care.score, constant).fit()\nprint(regression_result.summary())\n \nplt.scatter(health_care.Spend_Per_Capita_PPP, health_care.score)\nregression_function = regression_result.params[1] * health_care.Spend_Per_Capita_PPP + regression_result.params[0]\nregression_line = plt.plot(health_care.Spend_Per_Capita_PPP, regression_function, lw = 5, c = 'red', label = 'Regression Line')\nplt.xlabel('Spend_Per_Capita_PPP', fontsize = 15)\nplt.ylabel('score', fontsize = 15)\nplt.show()\n\nconstant = sm.add_constant(health_care.Spend_Public)\nregression_result = sm.OLS(health_care.score, constant).fit()\nprint(regression_result.summary())\n \nplt.scatter(health_care.Spend_Public, health_care.score)\nregression_function = regression_result.params[1] * health_care.Spend_Public + regression_result.params[0]\nregression_line = plt.plot(health_care.Spend_Public, regression_function, lw = 5, c = 'red', label = 'Regression Line')\nplt.xlabel('Spend_Public', fontsize = 15)\nplt.ylabel('score', fontsize = 15)\nplt.show()\n\nconstant = sm.add_constant(health_care.Nurse_per_1000)\nregression_result = sm.OLS(health_care.score, constant).fit()\nprint(regression_result.summary())\n \nplt.scatter(health_care.Nurse_per_1000, health_care.score)\nregression_function = regression_result.params[1] * health_care.Nurse_per_1000 + regression_result.params[0]\nregression_line = plt.plot(health_care.Nurse_per_1000, regression_function, lw = 5, c = 'red', label = 'Regression Line')\nplt.xlabel('Nurse_per_1000', fontsize = 15)\nplt.ylabel('score', fontsize = 15)\nplt.show()\n\nconstant = sm.add_constant(health_care.Physicians_per_1000)\nregression_result = sm.OLS(health_care.score, constant).fit()\nprint(regression_result.summary())\n \nplt.scatter(health_care.Physicians_per_1000, health_care.score)\nregression_function = regression_result.params[1] * health_care.Physicians_per_1000 + regression_result.params[0]\nregression_line = plt.plot(health_care.Physicians_per_1000, regression_function, lw = 5, c = 'red', label = 'Regression Line')\nplt.xlabel('Physicians_per_1000', fontsize = 15)\nplt.ylabel('score', fontsize = 15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"health_care.regression_models()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = ['Score']\npredictors = health_care.file_data.columns[7:].tolist()\ny = np.array(health_care.file_data[target])\n\nfig = plt.figure(figsize=(20,25))\n\nfor i, x in enumerate(predictors):\n    fig.add_subplot(7, 5, i+1)\n    plt.scatter(health_care.file_data[x], health_care.file_data['Score'])\n    plt.xlabel(x)\n    plt.ylabel('Score')\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skews = health_care.file_data.iloc[:, 7:].apply(lambda x: skew(x), axis=0)\nskewed = skews.index[skews > 1]\nskewed","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (20, 25))\n\nfor i, x in enumerate(skewed):\n    fig.add_subplot(7, 5, i + 1)\n    plt.scatter(np.log(health_care.file_data[x] + 10), health_care.file_data['Score'])\n    plt.xlabel(x)\n    plt.ylabel('Score')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class do_preprocess(BaseEstimator, TransformerMixin):\n    \n    def __init__(self, cols, scaler): \n        self.cols = cols\n        self.scaler = scaler\n    \n    def fit(self,X,y=None):\n        self.scaler.fit(X[self.cols])\n        return self\n    \n    def transform(self, X, y=None):\n        for col in self.cols:\n            if X[col].isna().sum()>0:\n                X1 = X[['Country',col]].groupby('Country')\n                previous = X1.fillna(method='bfill') \n                posterior = X1.fillna(method='ffill') \n                X[col] = (previous + posterior) / 2.0\n                X[col].fillna(method='ffill',inplace=True)\n                X[col].fillna(method='bfill',inplace=True)\n                \n            if skew(X[col]) > 1:\n                X[col] = np.log(X[col]+10)\n                X[col].fillna(X[col].min(),inplace=True)\n                \n        X[self.cols] = self.scaler.transform(X[self.cols])\n        X.index = X['ISO_3166-1_Alpha2'] + '2019'\n        return(X)\n    \ntarget = ['Score']\npredictors = health_care.file_data.columns[8:].tolist()\n\nrun_pipeline = Pipeline([('do_preprocess', do_preprocess(predictors, StandardScaler())),])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"health_care.file_data_preprocessed = run_pipeline.fit_transform(health_care.file_data.copy())\n\nhealth_care.file_data.isna().sum().plot.bar(figsize=(15,3),title='Nans before processing')\nplt.show()\n\nhealth_care.file_data.isna().sum().plot.bar(figsize=(15,3),title='Nans after processing')\nplt.show()\n\nhealth_care.file_data[predictors].plot.box(figsize=(15,5),title='Distribution before processing')\nplt.show()\n\nhealth_care.file_data_preprocessed[predictors].plot.box(figsize=(15,5),title='Distribution after processing')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(health_care.file_data_preprocessed[predictors+target])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix = health_care.file_data_preprocessed[predictors+target].corr(method='pearson')\nsns.clustermap(correlation_matrix, figsize=(15,15))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = sm.OLS(health_care.file_data_preprocessed[target], sm.add_constant(health_care.file_data_preprocessed[predictors]))\nmodel = model.fit()\n\nprint(model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"figure, ax = plt.subplots(figsize=(15,10))\nsm.graphics.influence_plot(model, ax=ax)\nfigure.tight_layout(pad=1.0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xall = np.array(health_care.file_data_preprocessed[predictors])\nyall = np.array(health_care.file_data_preprocessed[target])[:,0]\nXtrain, Xvalid, ytrain, yvalid = train_test_split(Xall, yall, test_size=0.25, random_state=2020)\n\nmodel = LinearRegression().fit(Xtrain, ytrain)\n\nypred = model.predict(Xvalid)\n\nprint('MSE = ', mean_squared_error(yvalid, ypred))\nprint('MAE = ', mean_absolute_error(yvalid, ypred))\n\nfigure, ax = plt.subplots(figsize=(15,5))\nplt.plot(ypred, yvalid-ypred, 'b.')\nax.axhline(y=0, color='k')\nplt.xlabel('Fitted values')\nplt.ylabel('Residuals')\nplt.title('Residual plot')\nplt.show()\n\nprint('Intercept=', model.intercept_)\npd.DataFrame({'Coefficient':model.coef_}, index=predictors).plot.bar(figsize=(15,5))\nplt.title('Predictor coefficients')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LinearSVR(max_iter = 10**6).fit(Xtrain, ytrain)\n\nypred = model.predict(Xvalid)\n\nprint('MSE = ', mean_squared_error(yvalid, ypred))\nprint('MAE = ', mean_absolute_error(yvalid, ypred))\n\nfigure, ax = plt.subplots(figsize=(15,5))\nplt.plot(ypred, yvalid-ypred, 'b.')\nax.axhline(y=0, color='k')\nplt.xlabel('Fitted values')\nplt.ylabel('Residuals')\nplt.title('Residual plot')\nplt.show()\n\npd.DataFrame({'Coefficient':model.coef_},index=predictors).plot.bar(figsize=(15,5))\nplt.title('Predictor coefficients')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.random.set_seed(1234)\n\ndef get_model():\n    tfin = tf.keras.layers.Input(shape=(Xtrain.shape[1],), name='X')\n    tf1 = tf.keras.layers.Dense(64,activation='linear')(tfin)\n    tfout = tf.keras.layers.Dense(units=1,activation='linear',name='out')(tf1)\n    model = tf.keras.Model(tfin, tfout)\n    model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n    return(model)\n\nmodel = get_model()\nhist = model.fit(x=Xtrain, y=ytrain, validation_data=(Xvalid,yvalid), verbose=0, epochs=20, batch_size=4)\n\nypred = model.predict(Xvalid)[:,0]\n\nprint('MSE = ',mean_squared_error(yvalid, ypred))\nprint('MAE = ',mean_absolute_error(yvalid, ypred))\n\nfigure, ax = plt.subplots(figsize=(15,5))\nplt.plot(ypred, yvalid-ypred, 'b.')\nax.axhline(y=0, color='k')\nplt.xlabel('Fitted values')\nplt.ylabel('Residuals')\nplt.title('Residual plot')\nplt.show()\n\nfigure = plt.figure()\nepochs = range(len(hist.history['loss']))\nplt.plot(hist.history['loss'],label='Training')\nplt.plot(hist.history['val_loss'],label='Validation')\nplt.legend()\nplt.title('Training and validation loss')\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Value\")\nfigure.set_size_inches(15,4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlation_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_data_new = run_pipeline.fit_transform(health_care.file_data.copy())\n\nmodel = LinearRegression()\nkfolds = KFold(n_splits=5, random_state=1989, shuffle=True)\nperformance = pd.DataFrame(np.zeros(len(predictors)), index=predictors,columns=['MSE'])\ncurrent = []\n\nfor i, x in enumerate(predictors):\n    \n    compare = [x for x in predictors if x not in current]\n    \n    performance = pd.DataFrame(np.zeros(len(compare)), index=compare,columns=['MSE'])\n    \n    for predictor in compare:\n        \n        X = np.array(file_data_new[current+[predictor]])\n        yp_test = np.zeros(len(y))\n        \n        for train_index, test_index in kfolds.split(X, y):\n            X_train, X_test = X[train_index], X[test_index]\n            y_train, y_test = y[train_index], y[test_index]\n            model.fit(X_train, y_train)\n            yp_test[test_index] = model.predict(X_test)[:,0]\n        \n        performance.loc[predictor] = mean_squared_error(y,yp_test)\n    \n    performance.sort_values(by='MSE', inplace=True)\n    current = current + [performance.index[0]]\n\n    X = np.array(file_data_new[current])\n    yp_test = np.zeros(len(y))\n    \n    for train_index, test_index in kfolds.split(X, y):\n        X_train, X_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n        model.fit(X_train, y_train)\n        yp_test[test_index] = model.predict(X_test)[:,0]\n\n    fig = plt.figure(figsize = (15,4))\n    ax = fig.add_subplot(1, 2, 1)\n    performance.plot.bar(ax = ax)\n    fig.add_subplot(1, 2, 2)    \n    plt.scatter(y, yp_test)\n    plt.xlabel('True values')\n    plt.ylabel('Predicted values')\n    plt.title(current[-1]+', MSE = ' + str(mean_squared_error(y, yp_test)))\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}